##そもそもDeep Learning とは?

とても簡単に言うとどんな入力に対しても欲しい出力を得られるような変換を目指す。  
基本的には*線形変換+非線形変換のセット*をたくさん(深く)重ねる。  
---

##Deep Learning は何をしているのか?

線形変換で大雑把に(線形で)再配置したものを非線形変換で曲面(超平面)で区切る。  
二次元で言うと二種類の点のプロットを大雑把に直線で区切った後、その直線を曲げてなるべく正確に分けられるようにするようなもの。  
---

##なぜ深く重ねるのか?

線形変換を重ねても、一つの線形変換で代用できる。  
だから、線形変換と非線形変換をセットにする。このセットが入力をどう出力に変えるかを決める。  
イメージ論になるが、セットを重ねると前のセットで区切ったものをさらに細かく区切ることができる。つまり、*重ねるほど複雑で繊細な分類*ができるようになる。  
---

##アルゴリズムと Deep Learning の違い

|アルゴリズム|                 Deep Learning|  
|人間の想定通りの挙動をする|   人間の想定外の見方を提示する(ことが多い)|  
|人間より高速な解答|           人間にできない部分の解答(も多い)|  
|論理的な問題に強い|           感覚的な問題に強い|  
---

##よく使われるパーツ(1/6)

*線形結合層*  
$$y = Wx+B$$  
WとBも行列。  
---

##よく使われるパーツ(2/6)

*畳み込み層*  
フィルター(カーネル)を一定の幅(ストライド)で動かして、カーネル自身とカーネルに重なった場所の行列積を返す。  
---

##よく使われるパーツ(3/6)

*max pooling層*  
フィルター(カーネル)が参照する領域の内で一番大きい値をとってくる。  
出てきた行列のサイズを減らす際に使われることが多い。  
---

##よく使われるパーツ(4/6)

*sigmoid関数*  
非線形変換に使われる。0-1で出力するので、値が大きくなりすぎることがない。   
$$y = \frec{1}{1+e^(-x)}$$  
---

##よく使われるパーツ(5/6)

*ReLU*  
非線形変換で使われる。簡単な関数だが、見た目通り非線形。  
$$y = \left\{
\begin{array}{||}
x & (x \geq 0)\\
0 & (x \lt 0)
\end{array}
\right.
$$
---

##よく使われるパーツ(6/6)

*softmax関数*  
主に分類問題に使われる。  
分類問題は(1)各値が0-1, (2)合計が1である必要がある。  
$$y_i = \frac{e^{x_i}}{\sum_{i = 0}^{N-1}e^{x_i}}$$  
---

##学習の仕組み(forward)

重ねた層の最初に入力データxを入れ、出力でyを受け取る。  
このyを使ってLoss Function(損失関数)というものを作り、計算する。  
損失関数は値が0以上となり、0の時想定される理想的な出力となるように設計する。  
損失関数を減らすように学習するので、損失関数の設計が学習の方向性を決める。  
---

##学習の仕組み(backward)

lossの値と学習率(学習の進み方)から出力の変化(誤差dy)を決め、それを入力層までさかのぼって更新可能なもの(カーネルの値やW,B)を更新していくことで、出力を最適化する。  
この際の問題点は二つあり、  
(1)誤差が微分系なので、lossが最小値でなくても、極小値なら学習が止まる。  
(2)学習データに適応しすぎると学習データ以外に対して性能が出なくなる。(過学習。汎化性能が落ちるともいう。)  
->例えば男女の分類で学習データが男子のみなら何が入ってきても男子と答えるように学習するかもしれない(学習データの選び方も大切)。
->lossが0に近づくことは学習データに適応していることを示すのみで汎化性能があるかは別の問題。  

---

##よく使う物たち

numpy 行列計算がとても早くなる。  
cupy  numpyの計算をGPUでも行う。  
tuple  (A,B,C)という形式。変更不可  
list   [a,b,c]という形式。変更可  
dictionary {'key':Value, }という形式。変更不可  
array  numpy,cupyの行列。計算が早いことが多い。  
Variable  chainerでそれまでの計算履歴を保持した値。Variableでないとbackwardが適切に行われない。forward,loss以外では基本的に重いだけなので、後述の.dataでarrayにすることが多い。  
.data  データを一段階抽象化する(イメージ)  
.shape arrayの形を知るのに使う。  
len()  listの長さを知るのに使う  

---

##実際に書いてみよう!

問題:手書き数字の分類(MNISTといわれるデータセット)  
参照:MNISTというファイル  
今後は実地で書いていきます。スライドは終わりです。おつかれさまでした。  